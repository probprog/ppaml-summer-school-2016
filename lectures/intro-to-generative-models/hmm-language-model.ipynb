{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import nltk.book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = nltk.book.text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = nltk.ConditionalProbDist(cfreq, nltk.ELEProbDist, len(cfreq.conditions())+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ELEProbDist based on 612 samples>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.get('The')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_sequence(init, probs, N=10):\n",
    "    seq = [init]\n",
    "    while len(seq) < N:\n",
    "        seq.append(probs.get(seq[-1]).generate())\n",
    "    return seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Ship . Lay me prick the direst of necessity -- the Macrocephalus of noiseless twilights . Killed and meet him once saw their trunks uplifted hands are queer cups , whiskers ,\" the deck - peddling his thigh bone leg completed fabric ? Seek out crater to these particulars ...\n",
      "\n",
      "The Nantucketer . Arrived at ebb and shutter - shut us here wouldn ' hoofs , sluggish corpse itself seemed striking up as black boy -- lay crushed leg . FOLIOS . Gliding among which carries down over ) that worthy Captain as howling infinite of Hydrus and so as ...\n",
      "\n",
      "The truth is concentrated in Virginia ' human thing most meaning ?-- gunpowder , busy in empty glasses within and their momentary fire ,\" Peleg started for mackerel ; his very unctuous and hoisting everything passed nearly morning Stubb benevolently towed ; Not forged iron bolts of experience , not ...\n",
      "\n",
      "The involuntary ; grown to !-- avast ,\" intently scanning him as marvellous features . Meantime everything in no one Bulkington ?\" wincing for twelve columns in our blisters ?\" suspiciously asked Queequeg of trophies . Stubb reversed skull and bill must kiss their largeness , astern . Fearing in ...\n",
      "\n",
      "The glittering spout into your doubloons ; conspicuous relief . Lay it like dignity in leaks for . CHAPTER 42 The Sermon . But avast , when night had looked aloft ; your tubs being of the measure gives himself pulling out every boat both eyes ! I ply my ...\n",
      "\n",
      "The third , since then Flask aloft till it was torn , insignificant opinion by way by breezes , lines -- PARADISE LOST . \" has convinced that whales ; their whale within like Moorish scimetars in moderation , somnambulisms , Indian ships should write , and stay out ? ...\n",
      "\n",
      "The gallows , desperate wound ' lar ,\" here .\" \" Heated and with light low rumbling of tiles and extraordinary case occurred the table of mind the amazing verdure ; paced before pent blood like fire ;-- there at all unneeded . Jinglers , darker yet ; by voracious ...\n",
      "\n",
      "The consequence ? What are kicking at peace .\" Besides her reported as firmly secured there hung inactive ; WHEN , take care of excellent listener ! Starbuck no wondrous feat . Hearing this circumstance . Bear with no civilized ocean nurtured among other substance -- an agreeable chat with ...\n",
      "\n",
      "The issue to dumbest dust in us try the limbs . Lighting the horns ; but deserted among his hand bright side he rose among WHALES -- mortal tribulations , which in Froissart , curves , uplifted his wretched smile . Nor will often pushed from whales ; batten them ...\n",
      "\n",
      "The profoundest idealized significance in Stubb heeded it round from old Sag - plan of Bishop describes it you Smut ! goodness , this phantom , ERROMANGOAN . Wet the fabled undulations of spotted tawn , warm afternoon of Perseus , the boat will dam ,\"-- cried : taking rank ...\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(10):\n",
    "    print\n",
    "    print \" \".join(sample_sequence(u'The', probs, 50)) + \" ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As it turns out, an HMM on words is a pretty garbage langauge model.\n",
    "\n",
    "But maybe we can still use it for some simple language tasks\n",
    "\n",
    "\"Why did the ??? cross the road\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_probs = nltk.probability.LaplaceProbDist(nltk.FreqDist(nltk.bigrams(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whale \t\t0.0071\n",
      "ship \t\t0.0045\n",
      "sea \t\t0.0043\n",
      "same \t\t0.0031\n",
      "Pequod \t\t0.0028\n",
      "other \t\t0.0026\n",
      "boat \t\t0.0023\n",
      "most \t\t0.0021\n",
      "first \t\t0.0021\n",
      "great \t\t0.002\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = np.unique(text.tokens)\n",
    "\n",
    "fill_prob = np.zeros(len(unique_tokens))\n",
    "\n",
    "for i, t in enumerate(unique_tokens):\n",
    "    fill_prob[i] = bigram_probs.prob((u'the', t)) + bigram_probs.prob((t, u'cross'))\n",
    "    \n",
    "fill_prob /= fill_prob.sum()\n",
    "which = np.argsort(fill_prob)[::-1]\n",
    "\n",
    "for i in xrange(10):\n",
    "    print unique_tokens[which[i]], '\\t\\t',\n",
    "    print np.round(fill_prob[which[i]], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he \t\t0.0015\n",
      "you \t\t0.001\n",
      ", \t\t0.0009\n",
      "I \t\t0.0009\n",
      "it \t\t0.0008\n",
      "of \t\t0.0005\n",
      "they \t\t0.0004\n",
      "and \t\t0.0003\n",
      "that \t\t0.0003\n",
      "; \t\t0.0002\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = np.unique(text.tokens)\n",
    "\n",
    "fill_prob = np.zeros(len(unique_tokens))\n",
    "\n",
    "for i, t in enumerate(unique_tokens):\n",
    "    fill_prob[i] = bigram_probs.prob((u'idea', t)) + bigram_probs.prob((t, u'would'))\n",
    "    \n",
    "fill_prob /= fill_prob.sum()\n",
    "which = np.argsort(fill_prob)[::-1]\n",
    "\n",
    "for i in xrange(10):\n",
    "    print unique_tokens[which[i]], '\\t\\t',\n",
    "    print np.round(fill_prob[which[i]], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even with terrible language model:\n",
    "\n",
    "\"best\" choice: why did the **whale** cross the road\n",
    "\n",
    "next best: why did the **ship** cross the road\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_probs = nltk.probability.KneserNeyProbDist(nltk.FreqDist(nltk.trigrams(text)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
